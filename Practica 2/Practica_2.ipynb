{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQu_Ue46PUBG"
      },
      "source": [
        "# Práctica 2: GPU Programming (CUDA)\n",
        "\n",
        "### Autores:\n",
        "Rafael Domínguez Sáez\n",
        "\n",
        "Iñigo Martínez Ciriza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rl6fk0zP0uX"
      },
      "source": [
        "## Preparación del entorno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdzBfLv1PjwG"
      },
      "source": [
        "Antes de nada debemos preparar el entorno de ejecución.\n",
        "\n",
        "Eliminación de datos innecesarios creados por Google Collab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qVsaiS2yPB8S"
      },
      "outputs": [],
      "source": [
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQj2UBZCP-co"
      },
      "source": [
        "Descarga de `Numba` en caso de no encontrarse en el sistema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jojn0H5qP7Yl",
        "outputId": "711aea82-eb93-42bb-9795-faaf1535a1c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.43.0)\n",
            "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install numba --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eWE1oOQQffG"
      },
      "source": [
        "Importación de los paquetes necesarios para el correcto funcionamiento del código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sU7PX7nzQfA-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float32\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv5Y84hHQsJC"
      },
      "source": [
        "## 2.1 Compulsory assignment #1: Matrix transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "it6U5yE7QwiG"
      },
      "outputs": [],
      "source": [
        "Ax = 5_000\n",
        "Ay = 7_000\n",
        "Bx = Ay\n",
        "By = Ax\n",
        "\n",
        "def create_matrix_1(Ax: int, Ay: int) -> tuple:\n",
        "  return np.random.rand(Ax, Ay), np.zeros((Ay, Ax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "i8oCTH7GRpOm"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def transpose_parallel(A, B):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < B.shape[0] and j < B.shape[1]:\n",
        "        B[i, j] = A[j, i]\n",
        "\n",
        "def transpose_sequential(A, B):\n",
        "    for i in range(0, B.shape[0]):\n",
        "        for j in range(0, B.shape[1]):\n",
        "            B[i, j] = A[j, i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDg9rArtSCfl",
        "outputId": "60e8defe-8335-43b7-f3cd-07fb889b623d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [[0.44486102 0.09760581 0.44534834 ... 0.11800538 0.24164943 0.25565313]\n",
            " [0.63799815 0.85673611 0.84667396 ... 0.146714   0.11202021 0.16948548]\n",
            " [0.18774264 0.94004216 0.50880155 ... 0.97488335 0.47848894 0.31737487]\n",
            " ...\n",
            " [0.38250947 0.48603796 0.8950678  ... 0.52787403 0.13116489 0.55453895]\n",
            " [0.46752753 0.81841218 0.58308125 ... 0.65193755 0.11150992 0.49548127]\n",
            " [0.77426633 0.39595189 0.98209078 ... 0.75678176 0.18726394 0.04267305]]\n",
            "\n",
            "Output \n",
            " [[0.44486102 0.63799815 0.18774264 ... 0.38250947 0.46752753 0.77426633]\n",
            " [0.09760581 0.85673611 0.94004216 ... 0.48603796 0.81841218 0.39595189]\n",
            " [0.44534834 0.84667396 0.50880155 ... 0.8950678  0.58308125 0.98209078]\n",
            " ...\n",
            " [0.11800538 0.146714   0.97488335 ... 0.52787403 0.65193755 0.75678176]\n",
            " [0.24164943 0.11202021 0.47848894 ... 0.13116489 0.11150992 0.18726394]\n",
            " [0.25565313 0.16948548 0.31737487 ... 0.55453895 0.49548127 0.04267305]]\n",
            "\n",
            "Tiempo ejecución en CPU = 18.126837730407715 s\n"
          ]
        }
      ],
      "source": [
        "A, B_seq = create_matrix_1(Ax, Ay)\n",
        "\n",
        "t_start = time.time()\n",
        "transpose_sequential(A, B_seq)\n",
        "t_finish = time.time()\n",
        "\n",
        "t_cpu = t_finish - t_start\n",
        "\n",
        "print(f\"Input \\n\", A)\n",
        "print()\n",
        "print(f\"Output \\n\", B_seq)\n",
        "print()\n",
        "print(f\"Tiempo ejecución en CPU = {t_cpu} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbjE5DA4Uwj4",
        "outputId": "4df995d6-c3cf-44ea-9c2a-fc98243813e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [[0.44486102 0.09760581 0.44534834 ... 0.11800538 0.24164943 0.25565313]\n",
            " [0.63799815 0.85673611 0.84667396 ... 0.146714   0.11202021 0.16948548]\n",
            " [0.18774264 0.94004216 0.50880155 ... 0.97488335 0.47848894 0.31737487]\n",
            " ...\n",
            " [0.38250947 0.48603796 0.8950678  ... 0.52787403 0.13116489 0.55453895]\n",
            " [0.46752753 0.81841218 0.58308125 ... 0.65193755 0.11150992 0.49548127]\n",
            " [0.77426633 0.39595189 0.98209078 ... 0.75678176 0.18726394 0.04267305]]\n",
            "\n",
            "Otuput \n",
            " [[0.44486102 0.63799815 0.18774264 ... 0.38250947 0.46752753 0.77426633]\n",
            " [0.09760581 0.85673611 0.94004216 ... 0.48603796 0.81841218 0.39595189]\n",
            " [0.44534834 0.84667396 0.50880155 ... 0.8950678  0.58308125 0.98209078]\n",
            " ...\n",
            " [0.11800538 0.146714   0.97488335 ... 0.52787403 0.65193755 0.75678176]\n",
            " [0.24164943 0.11202021 0.47848894 ... 0.13116489 0.11150992 0.18726394]\n",
            " [0.25565313 0.16948548 0.31737487 ... 0.55453895 0.49548127 0.04267305]]\n",
            "\n",
            "Tiempo ejecución en GPU = 1.7737162113189697 s\n"
          ]
        }
      ],
      "source": [
        "_, B_par = create_matrix_1(Ax, Ay)\n",
        "\n",
        "A_device = cuda.to_device(A)\n",
        "B_device = cuda.to_device(B_par)\n",
        "\n",
        "threads_per_block = (16, 16)\n",
        "\n",
        "blocks_X = math.ceil(B_par.shape[0] / threads_per_block[0])\n",
        "blocks_Y = math.ceil(B_par.shape[1] / threads_per_block[1])\n",
        "blocks_total = (blocks_X, blocks_Y)\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "transpose_parallel[blocks_total, threads_per_block](A_device, B_device)\n",
        "\n",
        "cuda.synchronize()\n",
        "t_finish = time.time()\n",
        "\n",
        "B_par = B_device.copy_to_host()\n",
        "\n",
        "t_gpu = t_finish - t_start\n",
        "\n",
        "print(\"Input \\n\", A)\n",
        "print()\n",
        "print(\"Otuput \\n\", B_par)\n",
        "print()\n",
        "print(f\"Tiempo ejecución en GPU = {t_gpu} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBnV5NOwbubU",
        "outputId": "87ce24a8-8e7b-4721-a4b1-8e55aa7d18d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speedup = 10.219694455477885\n"
          ]
        }
      ],
      "source": [
        "speedup = t_cpu / t_gpu\n",
        "\n",
        "print(f\"Speedup = {speedup}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU-MpuZbcsYf"
      },
      "source": [
        "## 2.2 Compulsory assignment #2: Average Rows/Cols I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b-a13FuccopR"
      },
      "outputs": [],
      "source": [
        "def Avg_Cols_sequential(input, output):\n",
        "    for y in range(input.shape[1]):\n",
        "        output[y] = 0.0\n",
        "        for x in range(input.shape[0]):\n",
        "            output[y] += input[x, y]\n",
        "        output[y] /= input.shape[0]\n",
        "\n",
        "def Avg_Rows_sequential(input, output):\n",
        "    for y in range(input.shape[0]):\n",
        "        output[y] = 0.0\n",
        "        for x in range(input.shape[1]):\n",
        "            output[y] += input[y, x]\n",
        "        output[y] /= input.shape[1]\n",
        "\n",
        "@cuda.jit\n",
        "def Avg_Cols_parallel(input, output):\n",
        "    y = cuda.grid(1)\n",
        "\n",
        "    if y < input.shape[1]:\n",
        "        sum_val = 0.0\n",
        "        for x in range(input.shape[0]):\n",
        "            sum_val += input[x, y]\n",
        "        output[y] = sum_val / input.shape[0]\n",
        "\n",
        "@cuda.jit\n",
        "def Avg_Rows_parallel(input, output):\n",
        "    y = cuda.grid(1)\n",
        "\n",
        "    if y < input.shape[0]:\n",
        "        sum_val = 0.0\n",
        "        for x in range(input.shape[1]):\n",
        "            sum_val += input[y, x]\n",
        "        output[y] = sum_val / input.shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MsUpbLgbdA5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "796b73d0-5534-402c-e7a3-c77faf0630f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [[0.5488135  0.71518937 0.60276338 ... 0.83000295 0.93280618 0.30833843]\n",
            " [0.29264205 0.56651827 0.13741443 ... 0.80182819 0.5391446  0.83721853]\n",
            " [0.4577597  0.3769177  0.70233513 ... 0.84348096 0.94290928 0.83282242]\n",
            " ...\n",
            " [0.45568019 0.05480491 0.25982542 ... 0.10151857 0.47639488 0.7728146 ]\n",
            " [0.47772193 0.61759916 0.66554051 ... 0.63370207 0.7252492  0.75827622]\n",
            " [0.2176855  0.35912559 0.78489484 ... 0.25148401 0.36997825 0.72145565]]\n",
            "\n",
            "Output CPU \n",
            " [0.49843221 0.49760128 0.49841932 ... 0.50760745 0.50385554 0.50377579]\n",
            "\n",
            "Tiempo ejecución en CPU = 11.211371183395386 s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 125 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output GPU \n",
            " [0.49843221 0.49760128 0.49841932 ... 0.50760745 0.50385554 0.50377579]\n",
            "\n",
            "Tiempo ejecución en GPU = 0.24784374237060547 s\n",
            "\n",
            "Speedup = 45.235643539592814\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "Ax = 4_000\n",
        "Ay = 4_000\n",
        "\n",
        "A = np.random.rand(Ax, Ay)\n",
        "\n",
        "# CPU\n",
        "B_cpu_cols = np.zeros(Ay)\n",
        "\n",
        "t_start = time.time()\n",
        "Avg_Cols_sequential(A, B_cpu_cols)\n",
        "t_finish = time.time()\n",
        "\n",
        "t_cpu_cols = t_finish - t_start\n",
        "\n",
        "print(\"Input \\n\", A)\n",
        "print()\n",
        "print(\"Output CPU \\n\", B_cpu_cols)\n",
        "print()\n",
        "print(f\"Tiempo ejecución en CPU = {t_cpu_cols} s\")\n",
        "print()\n",
        "\n",
        "# GPU\n",
        "B_gpu_cols = np.zeros(Ay)\n",
        "\n",
        "A_device = cuda.to_device(A)\n",
        "B_device = cuda.to_device(B_gpu_cols)\n",
        "\n",
        "threads_per_block = 32\n",
        "blocks_total = math.ceil(A_device.shape[1] / threads_per_block)\n",
        "\n",
        "t_start = time.time()\n",
        "Avg_Cols_parallel[blocks_total, threads_per_block](A_device, B_device)\n",
        "cuda.synchronize()\n",
        "t_finish = time.time()\n",
        "\n",
        "B_gpu_cols = B_device.copy_to_host()\n",
        "t_gpu_cols = t_finish - t_start\n",
        "\n",
        "print(\"Output GPU \\n\", B_gpu_cols)\n",
        "print()\n",
        "print(f\"Tiempo ejecución en GPU = {t_gpu_cols} s\")\n",
        "print()\n",
        "\n",
        "# Speedup\n",
        "speedup = t_cpu_cols / t_gpu_cols\n",
        "print(f\"Speedup = {speedup}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "B_cpu_rows = np.zeros(Ax)\n",
        "\n",
        "t_start = time.time()\n",
        "Avg_Rows_sequential(A, B_cpu_rows)\n",
        "t_finish = time.time()\n",
        "\n",
        "t_cpu_rows = t_finish - t_start\n",
        "\n",
        "print(\"Input \\n\", A)\n",
        "print()\n",
        "print(\"Output CPU \\n\", B_cpu_rows)\n",
        "print()\n",
        "print(f\"Tiempo ejecución en CPU = {t_cpu_rows} s\")\n",
        "print()\n",
        "\n",
        "# GPU\n",
        "B_gpu_rows = np.zeros(Ax)\n",
        "\n",
        "A_device = cuda.to_device(A)\n",
        "B_device = cuda.to_device(B_gpu_rows)\n",
        "\n",
        "threads_per_block = 32\n",
        "blocks_total = math.ceil(A_device.shape[0] / threads_per_block)\n",
        "\n",
        "t_start = time.time()\n",
        "Avg_Rows_parallel[blocks_total, threads_per_block](A_device, B_device)\n",
        "cuda.synchronize()\n",
        "t_finish = time.time()\n",
        "\n",
        "B_gpu_rows = B_device.copy_to_host()\n",
        "t_gpu_rows = t_finish - t_start\n",
        "\n",
        "print(\"Output GPU \\n\", B_gpu_rows)\n",
        "print()\n",
        "print(f\"Tiempo ejecución en GPU = {t_gpu_rows} s\")\n",
        "print()\n",
        "\n",
        "# Speedup\n",
        "speedup = t_cpu_rows / t_gpu_rows\n",
        "print(f\"Speedup = {speedup}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyn_nRxkRdPF",
        "outputId": "68cbb36e-1612-4cb3-caf0-660f6ab9ffd8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [[0.5488135  0.71518937 0.60276338 ... 0.83000295 0.93280618 0.30833843]\n",
            " [0.29264205 0.56651827 0.13741443 ... 0.80182819 0.5391446  0.83721853]\n",
            " [0.4577597  0.3769177  0.70233513 ... 0.84348096 0.94290928 0.83282242]\n",
            " ...\n",
            " [0.45568019 0.05480491 0.25982542 ... 0.10151857 0.47639488 0.7728146 ]\n",
            " [0.47772193 0.61759916 0.66554051 ... 0.63370207 0.7252492  0.75827622]\n",
            " [0.2176855  0.35912559 0.78489484 ... 0.25148401 0.36997825 0.72145565]]\n",
            "\n",
            "Output CPU \n",
            " [0.49910374 0.49199426 0.49593635 ... 0.50096485 0.50020686 0.4928522 ]\n",
            "\n",
            "Tiempo ejecución en CPU = 9.331703901290894 s\n",
            "\n",
            "Output GPU \n",
            " [0.49910374 0.49199426 0.49593635 ... 0.50096485 0.50020686 0.4928522 ]\n",
            "\n",
            "Tiempo ejecución en GPU = 0.18918156623840332 s\n",
            "\n",
            "Speedup = 49.32670812932822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 125 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-JgxtFQ6n-g"
      },
      "source": [
        "## 2.3 Compulsory assignment #3: Average Rows/Cols II (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lablhRLX6rXR"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def Avg_Cols_parallel_shared(input, output):\n",
        "    shared_mem = cuda.shared.array(shape=(32,), dtype=float32)\n",
        "    rows, cols = input.shape\n",
        "    y = cuda.grid(1)\n",
        "    tx = cuda.threadIdx.x\n",
        "\n",
        "    if y < cols:\n",
        "        shared_mem[tx] = 0.0\n",
        "        cuda.syncthreads()\n",
        "        for x in range(rows):\n",
        "            cuda.atomic.add(shared_mem, tx, input[x, y])\n",
        "        cuda.syncthreads()\n",
        "        output[y] = shared_mem[tx] / rows\n",
        "\n",
        "@cuda.jit\n",
        "def Avg_Rows_parallel_shared(input, output):\n",
        "    shared_mem = cuda.shared.array(shape=(32,), dtype=float32)\n",
        "    rows, cols = input.shape\n",
        "    x = cuda.grid(1)\n",
        "    tx = cuda.threadIdx.x\n",
        "\n",
        "    if tx < rows:\n",
        "        shared_mem[tx] = 0.0\n",
        "        cuda.syncthreads()\n",
        "        for y in range(cols):\n",
        "            cuda.atomic.add(shared_mem, tx, input[x, y])\n",
        "        cuda.syncthreads()\n",
        "        output[x] = shared_mem[tx] / cols"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU SHARED\n",
        "B_gpu_cols_shared = np.zeros(Ay)\n",
        "\n",
        "B_device = cuda.to_device(B_gpu_cols_shared)\n",
        "\n",
        "threads_per_block = 32\n",
        "blocks_total = math.ceil(A_device.shape[1] / threads_per_block)\n",
        "\n",
        "t_start = time.time()\n",
        "Avg_Cols_parallel_shared[blocks_total, threads_per_block](A_device, B_device)\n",
        "t_finish = time.time()\n",
        "\n",
        "B_gpu_cols_shared = B_device.copy_to_host()\n",
        "t_gpu_cols_shared = t_finish - t_start\n",
        "\n",
        "print(\"Output GPU \\n\", B_gpu_cols)\n",
        "print()\n",
        "print(\"Output GPU memoria compartida \\n\", B_gpu_cols_shared)\n",
        "print()\n",
        "print(f\"Tiempo ejecución en GPU con memoria compartida = {t_gpu_cols_shared} s\")\n",
        "print()\n",
        "\n",
        "# Speedup\n",
        "speedup = t_cpu_cols / t_gpu_cols_shared\n",
        "print(f\"Speedup = {speedup}\")\n",
        "\n",
        "speedup = t_gpu_cols / t_gpu_cols_shared\n",
        "print(f\"Speedup memoria compartida = {speedup}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m72-Yt_Wq2s",
        "outputId": "66476b90-8e4b-49a4-d2c1-f41fe6b3b244"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 125 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output GPU \n",
            " [0.49843221 0.49760128 0.49841932 ... 0.50760745 0.50385554 0.50377579]\n",
            "\n",
            "Output GPU memoria compartida \n",
            " [0.49843121 0.4976011  0.49841986 ... 0.50760754 0.50385571 0.50377637]\n",
            "\n",
            "Tiempo ejecución en GPU con memoria compartida = 0.28505802154541016 s\n",
            "\n",
            "Speedup = 39.33013750188187\n",
            "Speedup memoria compartida = 0.8694501597497533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU SHARED\n",
        "B_gpu_rows_shared = np.zeros(Ax)\n",
        "\n",
        "B_device = cuda.to_device(B_gpu_rows_shared)\n",
        "\n",
        "threads_per_block = 32\n",
        "blocks_total = math.ceil(A_device.shape[0] / threads_per_block)\n",
        "\n",
        "t_start = time.time()\n",
        "Avg_Rows_parallel_shared[blocks_total, threads_per_block](A_device, B_device)\n",
        "t_finish = time.time()\n",
        "\n",
        "B_gpu_rows_shared = B_device.copy_to_host()\n",
        "t_gpu_rows_shared = t_finish - t_start\n",
        "\n",
        "print(\"Output GPU \\n\", B_gpu_rows)\n",
        "print()\n",
        "print(\"Output GPU memoria compartida \\n\", B_gpu_rows_shared)\n",
        "print()\n",
        "print(f\"Tiempo ejecución en GPU con memoria compartida = {t_gpu_rows_shared} s\")\n",
        "print()\n",
        "\n",
        "# Speedup\n",
        "speedup = t_cpu_rows / t_gpu_rows_shared\n",
        "print(f\"Speedup = {speedup}\")\n",
        "\n",
        "speedup = t_gpu_rows / t_gpu_rows_shared\n",
        "print(f\"Speedup memoria compartida = {speedup}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPrz2fNkX8t9",
        "outputId": "51fb8d21-0e69-47ef-8750-baa79ad4ffbd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 125 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output GPU \n",
            " [0.49910374 0.49199426 0.49593635 ... 0.50096485 0.50020686 0.4928522 ]\n",
            "\n",
            "Output GPU memoria compartida \n",
            " [0.49910382 0.49199466 0.49593689 ... 0.50096503 0.50020764 0.49285245]\n",
            "\n",
            "Tiempo ejecución en GPU con memoria compartida = 0.2787179946899414 s\n",
            "\n",
            "Speedup = 33.480808842901965\n",
            "Speedup memoria compartida = 0.6787561974563483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8EQzO8h6EuU"
      },
      "source": [
        "## 2.4 Optional assignment #1: Mean_3x3 (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dDP9905M6Kdr"
      },
      "outputs": [],
      "source": [
        "def Mean_3x3_sequential(input, output):\n",
        "    for x in range(input.shape[0]):\n",
        "        for y in range(input.shape[1]):\n",
        "            output[x, y] = 0.0\n",
        "            for i in range(-1, 2):\n",
        "                for j in range(-1, 2):\n",
        "                    if x + i >= 0 and x + i < input.shape[0] and \\\n",
        "                        y + j >= 0 and y + j < input.shape[1]:\n",
        "                        output[x, y] += input[x + i, y + j]\n",
        "            output[x, y] /= 9.0\n",
        "\n",
        "@cuda.jit\n",
        "def Mean_3x3_parallel(input, output):\n",
        "    shared_mem = cuda.shared.array((16 + 2, 16 + 2), dtype=float32)\n",
        "    rows, cols = input.shape\n",
        "    x, y = cuda.grid(2)\n",
        "\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "\n",
        "    if 0 <= x < rows and 0 <= y < cols:\n",
        "        shared_mem[tx + 1, ty + 1] = input[x, y]\n",
        "    else:\n",
        "        shared_mem[tx + 1, ty + 1] = 0.0\n",
        "\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    # Calcular la media 3x3 si estamos dentro del rango\n",
        "    if x < rows and y < cols:\n",
        "        total_sum = 0.0\n",
        "        if y != 0 and y != cols-1 and x != 0 and x != rows-1:\n",
        "            # Sumar los 8 vecinos y la celda central\n",
        "            total_sum = (shared_mem[tx, ty] + shared_mem[tx, ty + 1] + shared_mem[tx, ty + 2] +\n",
        "                        shared_mem[tx + 1, ty] + shared_mem[tx + 1, ty + 1] + shared_mem[tx + 1, ty + 2] +\n",
        "                        shared_mem[tx + 2, ty] + shared_mem[tx + 2, ty + 1] + shared_mem[tx + 2, ty + 2])\n",
        "        elif y == 0 and x == 0:\n",
        "            total_sum = (shared_mem[tx + 1, ty + 1] + shared_mem[tx + 1, ty + 2] +\n",
        "                         shared_mem[tx + 2, ty + 1] + shared_mem[tx + 2, ty + 2])\n",
        "        elif y == 0 and x == rows-1:\n",
        "            total_sum = (shared_mem[tx, ty + 1]     +  shared_mem[tx, ty + 2] +\n",
        "                         shared_mem[tx + 1, ty + 1] +  shared_mem[tx + 1, ty + 2])\n",
        "        elif y == cols-1 and x == rows-1:\n",
        "            total_sum = (shared_mem[tx, ty]    +  shared_mem[tx, ty + 1] +\n",
        "                        shared_mem[tx + 1, ty] +  shared_mem[tx + 1, ty + 1])\n",
        "        elif y == cols-1 and x == 0:\n",
        "            total_sum = (shared_mem[tx + 1, ty] + shared_mem[tx + 1, ty + 1] +\n",
        "                         shared_mem[tx + 2, ty] + shared_mem[tx + 2, ty + 1])\n",
        "        elif y == 0:\n",
        "            total_sum = (shared_mem[tx, ty + 1] + shared_mem[tx, ty + 2] +\n",
        "                        shared_mem[tx + 1, ty + 1] + shared_mem[tx + 1, ty + 2] +\n",
        "                        shared_mem[tx + 2, ty + 1] + shared_mem[tx + 2, ty + 2])\n",
        "        elif y == cols-1:\n",
        "            total_sum = (shared_mem[tx, ty] + shared_mem[tx, ty + 1] +\n",
        "                        shared_mem[tx + 1, ty] + shared_mem[tx + 1, ty + 1] +\n",
        "                        shared_mem[tx + 2, ty] + shared_mem[tx + 2, ty + 1])\n",
        "        elif x == 0:\n",
        "            total_sum = (shared_mem[tx + 1, ty] + shared_mem[tx + 1, ty + 1] + shared_mem[tx + 1, ty + 2] +\n",
        "                        shared_mem[tx + 2, ty] + shared_mem[tx + 2, ty + 1] + shared_mem[tx + 2, ty + 2])\n",
        "        elif x == rows-1:\n",
        "            total_sum = (shared_mem[tx, ty] + shared_mem[tx, ty + 1] + shared_mem[tx, ty + 2] +\n",
        "                        shared_mem[tx + 1, ty] + shared_mem[tx + 1, ty + 1] + shared_mem[tx + 1, ty + 2])\n",
        "\n",
        "        output[x, y] = total_sum / 9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TOOoL1fg77Fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c43214-42ae-489d-d8f5-c688619ca7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [[0.5488135  0.71518937 0.60276338 ... 0.40171354 0.24841347 0.50586638]\n",
            " [0.31038083 0.37303486 0.52497044 ... 0.93841202 0.22864655 0.67714114]\n",
            " [0.59288027 0.0100637  0.4758262  ... 0.11224999 0.04236405 0.22774099]\n",
            " ...\n",
            " [0.04027885 0.47565007 0.23954916 ... 0.86257219 0.78585522 0.86425687]\n",
            " [0.26993482 0.42351381 0.63561855 ... 0.56271762 0.35168929 0.28798926]\n",
            " [0.21022704 0.09253358 0.75865814 ... 0.50272661 0.68693019 0.1843027 ]]\n",
            "\n",
            "Output \n",
            " [[0.21637984 0.3416836  0.39015958 ... 0.30972799 0.33335479 0.18445195]\n",
            " [0.28337361 0.46154695 0.52289962 ... 0.34842103 0.37583868 0.21446362]\n",
            " [0.28557148 0.42141822 0.4884467  ... 0.43059867 0.4280333  0.25794777]\n",
            " ...\n",
            " [0.31307159 0.48448196 0.51958307 ... 0.63846398 0.6379794  0.42470454]\n",
            " [0.16801535 0.34955156 0.47562152 ... 0.57647788 0.56544888 0.35122484]\n",
            " [0.11068992 0.26560955 0.37219746 ... 0.28558861 0.28626174 0.16787905]]\n",
            "\n",
            "Tiempo ejecución en CPU = 2.6276276111602783 s\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "Ax = 500\n",
        "Ay = 500\n",
        "A = np.random.rand(Ax, Ay)\n",
        "B = np.zeros_like(A)\n",
        "\n",
        "t_start = time.time()\n",
        "Mean_3x3_sequential(A, B)\n",
        "t_finish = time.time()\n",
        "\n",
        "t_cpu = t_finish - t_start\n",
        "\n",
        "print(\"Input \\n\", A)\n",
        "print()\n",
        "print(\"Output \\n\", B)\n",
        "print()\n",
        "print(f\"Tiempo ejecución en CPU = {t_cpu} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "YoXI_YDgBW6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d74dd09-ee3a-4537-ff3b-02f1df12f93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [[0.5488135  0.71518937 0.60276338 ... 0.40171354 0.24841347 0.50586638]\n",
            " [0.31038083 0.37303486 0.52497044 ... 0.93841202 0.22864655 0.67714114]\n",
            " [0.59288027 0.0100637  0.4758262  ... 0.11224999 0.04236405 0.22774099]\n",
            " ...\n",
            " [0.04027885 0.47565007 0.23954916 ... 0.86257219 0.78585522 0.86425687]\n",
            " [0.26993482 0.42351381 0.63561855 ... 0.56271762 0.35168929 0.28798926]\n",
            " [0.21022704 0.09253358 0.75865814 ... 0.50272661 0.68693019 0.1843027 ]]\n",
            "\n",
            "Output \n",
            " [[0.21637983 0.3416836  0.39015961 ... 0.30972799 0.33335479 0.18445195]\n",
            " [0.28337359 0.46154695 0.52289963 ... 0.34842104 0.3758387  0.21446362]\n",
            " [0.28557147 0.42141822 0.48844671 ... 0.43059868 0.42803327 0.25794776]\n",
            " ...\n",
            " [0.31307162 0.48448202 0.51958312 ... 0.63846397 0.63797935 0.42470455]\n",
            " [0.16801535 0.34955155 0.47562154 ... 0.5764779  0.56544892 0.35122485]\n",
            " [0.11068992 0.26560956 0.37219744 ... 0.28558861 0.28626174 0.16787904]]\n",
            "\n",
            "Tiempo ejecución en GPU = 0.0004222393035888672 s\n"
          ]
        }
      ],
      "source": [
        "B = np.zeros_like(A)\n",
        "\n",
        "A_device = cuda.to_device(A)\n",
        "B_device = cuda.to_device(B)\n",
        "\n",
        "threads_per_block = (16,16)\n",
        "\n",
        "blocks_X = math.ceil(B.shape[0] / threads_per_block[0])\n",
        "blocks_Y = math.ceil(B.shape[1] / threads_per_block[1])\n",
        "blocks_total = (blocks_X, blocks_Y)\n",
        "\n",
        "t_start = time.time()\n",
        "Mean_3x3_parallel[blocks_total, threads_per_block](A_device, B_device)\n",
        "t_finish = time.time()\n",
        "\n",
        "t_gpu = t_finish - t_start\n",
        "\n",
        "B_par = B_device.copy_to_host()\n",
        "\n",
        "print(\"Input \\n\", A)\n",
        "print()\n",
        "print(\"Output \\n\", B_par)\n",
        "print()\n",
        "print(f\"Tiempo ejecución en GPU = {t_gpu} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "J9737m5aOwhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d234f334-612e-47ed-8c32-2385974057c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speedup = 4.731156187370015\n"
          ]
        }
      ],
      "source": [
        "speedup = t_cpu / t_gpu\n",
        "print(f\"Speedup = {speedup}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNJsCS_POCqU"
      },
      "source": [
        "# Optional assignment #2: Reduction approaches (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-yK9GZG6Wr7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c76735d-701b-4702-8dab-3b020ef1e96c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [0.5488135  0.71518937 0.60276338 ... 0.7016828  0.45616281 0.14553608]\n",
            "\n",
            "Output \n",
            " 4999995.59696607\n",
            "\n",
            "Tiempo ejecución en CPU = 1.5949816703796387 s\n"
          ]
        }
      ],
      "source": [
        "def Reduce_sequential(input, output):\n",
        "    acum = 0\n",
        "    for i in range(input.shape[0]):\n",
        "        acum += input[i]\n",
        "    output[0] = acum\n",
        "\n",
        "\n",
        "N = 10_000_000\n",
        "np.random.seed(0)\n",
        "A = np.random.rand(N)\n",
        "output = np.zeros(1)\n",
        "\n",
        "t_start = time.time()\n",
        "Reduce_sequential(A, output)\n",
        "t_finish = time.time()\n",
        "\n",
        "t_cpu = t_finish - t_start\n",
        "\n",
        "print(\"Input \\n\", A)\n",
        "print()\n",
        "print(\"Output \\n\", output[0])\n",
        "print()\n",
        "print(f\"Tiempo ejecución en CPU = {t_cpu} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUrHrvK1Wk-d"
      },
      "source": [
        "## Reduction #1: Interleaved addressing with divergent branching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "twNQAnUJOCHb"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def reduce_interleaved_divergent(input, output):\n",
        "    sSrc = cuda.shared.array(16, dtype=float32)\n",
        "    sDst = cuda.shared.array(16, dtype=float32)\n",
        "\n",
        "\n",
        "    tid = cuda.threadIdx.x\n",
        "    bid = cuda.blockIdx.x\n",
        "    bx = cuda.blockDim.x\n",
        "\n",
        "    if tid + bid * bx < input.size:\n",
        "        sSrc[tid] = input[tid + bid * bx]\n",
        "    else:\n",
        "        sSrc[tid] = 0\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    stride = 2\n",
        "    while stride <= bx:\n",
        "        if tid % stride == 0:\n",
        "            if tid + stride // 2 < bx:\n",
        "                # sSrc[tid + stride // 2]\n",
        "                sDst[tid] = sSrc[tid] + sSrc[tid + stride // 2]\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        sSrc[tid] = sDst[tid]\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        # Como se indica arriba, se multiplica stride * 2\n",
        "        stride *= 2\n",
        "\n",
        "    # El primer hilo de todos tiene el privilegio de guardar el resultado\n",
        "    if tid == 0:\n",
        "        cuda.atomic.add(output, 0, sDst[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EXk9iR_PQMnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d90350a-f18f-4428-d2eb-aefc85287440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [0.5488135  0.71518937 0.60276338 ... 0.7016828  0.45616281 0.14553608]\n",
            "\n",
            "Output \n",
            " 4999995.596932173\n",
            "\n",
            "Tiempo ejecución en GPU = 0.18361759185791016 s\n"
          ]
        }
      ],
      "source": [
        "output = np.zeros(1)\n",
        "\n",
        "input_device = cuda.to_device(A)\n",
        "output_device = cuda.to_device(output)\n",
        "\n",
        "threads_per_block = 16\n",
        "blocks_per_grid = math.ceil(N + threads_per_block - 1 / threads_per_block)\n",
        "\n",
        "#TODO: calculo del tiempo en gpu\n",
        "t_start = time.time()\n",
        "reduce_interleaved_divergent[blocks_per_grid, threads_per_block](input_device, output_device)\n",
        "t_finish = time.time()\n",
        "\n",
        "t_gpu_1 = t_finish - t_start\n",
        "\n",
        "output = output_device.copy_to_host()\n",
        "\n",
        "print(\"Input \\n\", A)\n",
        "print()\n",
        "print(\"Output \\n\", output[0])\n",
        "print()\n",
        "print(f\"Tiempo ejecución en GPU = {t_gpu_1} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Eh3Kr21cOwhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe4cefd-7819-4152-8d85-db71ab1591e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speedup = 8.6864316988423\n"
          ]
        }
      ],
      "source": [
        "speedup = t_cpu / t_gpu_1\n",
        "print(f\"Speedup = {speedup}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfa_IwVUXVxp"
      },
      "source": [
        "## Reduction #2: Interleaved addressing with no divergent branching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "L36WqhwRXHj0"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def reduce_interleaved_no_divergent(input, output):\n",
        "    sSrc = cuda.shared.array(shape=16, dtype=float32)\n",
        "    tid = cuda.threadIdx.x\n",
        "    bid = cuda.blockIdx.x\n",
        "    bx = cuda.blockDim.x\n",
        "\n",
        "    idx = tid + bid * bx\n",
        "    if idx < input.size:\n",
        "        sSrc[tid] = input[idx]\n",
        "    else:\n",
        "        sSrc[tid] = 0.0\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    stride = 1\n",
        "    while stride < bx:\n",
        "        index = tid + stride\n",
        "        if index < bx:\n",
        "            sSrc[tid] += sSrc[index]\n",
        "        cuda.syncthreads()\n",
        "        stride *= 2\n",
        "\n",
        "    if tid == 0:\n",
        "        cuda.atomic.add(output, 0, sSrc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wS3a2SYlXLAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e145336-6e81-4559-b706-e1b876aa2647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [0.5488135  0.71518937 0.60276338 ... 0.7016828  0.45616281 0.14553608]\n",
            "\n",
            "Output \n",
            " 4999995.596932173\n",
            "\n",
            "Tiempo ejecución en GPU = 0.18361759185791016 s\n"
          ]
        }
      ],
      "source": [
        "output = np.zeros(1)\n",
        "\n",
        "input_device = cuda.to_device(A)\n",
        "output_device = cuda.to_device(output)\n",
        "\n",
        "threads_per_block = 16\n",
        "blocks_per_grid = math.ceil(N + threads_per_block - 1 / threads_per_block)\n",
        "\n",
        "t_start = time.time()\n",
        "reduce_interleaved_no_divergent[blocks_per_grid, threads_per_block](input_device, output_device)\n",
        "t_finish = time.time()\n",
        "\n",
        "t_gpu_2 = t_finish - t_start\n",
        "\n",
        "output = output_device.copy_to_host()\n",
        "\n",
        "print(\"Input \\n\", A)\n",
        "print()\n",
        "print(\"Output \\n\", output[0])\n",
        "print()\n",
        "print(f\"Tiempo ejecución en GPU = {t_gpu_1} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "51DKECBqOwhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e556b94-6041-4e47-fbda-0b772c32507e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speedup = 10.142910858484015\n"
          ]
        }
      ],
      "source": [
        "speedup = t_cpu / t_gpu_2\n",
        "print(f\"Speedup = {speedup}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1v0BTGbX3kj"
      },
      "source": [
        "## Reduction #3: Sequential addressing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_fvyOQncX1I3"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def reduce_sequential_addressing(input, output):\n",
        "    sSrc = cuda.shared.array(16, dtype=float32)\n",
        "\n",
        "    tid = cuda.threadIdx.x\n",
        "    bid = cuda.blockIdx.x\n",
        "    bx = cuda.blockDim.x\n",
        "\n",
        "    if tid + bid * bx < input.size:\n",
        "        sSrc[tid] = input[tid + bid * bx]\n",
        "    else:\n",
        "        sSrc[tid] = 0\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    stride = 1\n",
        "    while stride < bx:\n",
        "        index = 2 * stride * tid\n",
        "        if index + stride < bx:\n",
        "            sSrc[index] += sSrc[index + stride]\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        stride *= 2\n",
        "\n",
        "    if tid == 0:\n",
        "        cuda.atomic.add(output, 0, sSrc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "riO6z0hCX76H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5584d7bf-81b5-49a3-9405-c260a50eeca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [0.5488135  0.71518937 0.60276338 ... 0.7016828  0.45616281 0.14553608]\n",
            "\n",
            "Output \n",
            " 4999995.596932173\n",
            "\n",
            "Tiempo ejecución en GPU = 0.18361759185791016 s\n"
          ]
        }
      ],
      "source": [
        "output = np.zeros(1)\n",
        "\n",
        "input_device = cuda.to_device(A)\n",
        "output_device = cuda.to_device(output)\n",
        "\n",
        "threads_per_block = 16\n",
        "blocks_per_grid = math.ceil(N + threads_per_block - 1 / threads_per_block)\n",
        "\n",
        "t_start = time.time()\n",
        "reduce_sequential_addressing[blocks_per_grid, threads_per_block](input_device, output_device)\n",
        "t_finish = time.time()\n",
        "\n",
        "t_gpu_3 = t_finish - t_start\n",
        "\n",
        "output = output_device.copy_to_host()\n",
        "\n",
        "print(\"Input \\n\", A)\n",
        "print()\n",
        "print(\"Output \\n\", output[0])\n",
        "print()\n",
        "print(f\"Tiempo ejecución en GPU = {t_gpu_1} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Iiq28zk4Owhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2cec150-220a-49fc-c54c-c627cfab0038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speedup = 7.758717750961165\n"
          ]
        }
      ],
      "source": [
        "speedup = t_cpu / t_gpu_3\n",
        "print(f\"Speedup = {speedup}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-wRqWP7YXAb"
      },
      "source": [
        "## Reduction #4: Atomic addition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "I3BOSmW_YQvQ"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def reduce_atomic_addition(input, output):\n",
        "\n",
        "    partial_sum = cuda.shared.array(16, dtype=float32)\n",
        "\n",
        "    tid = cuda.threadIdx.x\n",
        "    bid = cuda.blockIdx.x\n",
        "    bx = cuda.blockDim.x\n",
        "\n",
        "    if tid == 0:\n",
        "        partial_sum[0] = 0.0\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    if tid + bid * bx < input.size:\n",
        "        cuda.atomic.add(partial_sum, 0, input[tid + bid * bx])\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    if tid == 0:\n",
        "        cuda.atomic.add(output, 0, partial_sum[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "tSUni8DwYea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f597d3-0c95-4029-cdb2-4cb71b09ddd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input \n",
            " [0.5488135  0.71518937 0.60276338 ... 0.7016828  0.45616281 0.14553608]\n",
            "\n",
            "Output \n",
            " 4999995.597110033\n",
            "\n",
            "Tiempo ejecución en GPU = 0.18361759185791016 s\n"
          ]
        }
      ],
      "source": [
        "output = np.zeros(1)\n",
        "\n",
        "input_device = cuda.to_device(A)\n",
        "output_device = cuda.to_device(output)\n",
        "\n",
        "threads_per_block = 16\n",
        "blocks_per_grid = math.ceil(N + threads_per_block - 1 / threads_per_block)\n",
        "\n",
        "t_start = time.time()\n",
        "reduce_atomic_addition[blocks_per_grid, threads_per_block](input_device, output_device)\n",
        "t_finish = time.time()\n",
        "\n",
        "t_gpu_atom = t_finish - t_start\n",
        "\n",
        "output = output_device.copy_to_host()\n",
        "\n",
        "print(\"Input \\n\", A)\n",
        "print()\n",
        "print(\"Output \\n\", output[0])\n",
        "print()\n",
        "print(f\"Tiempo ejecución en GPU = {t_gpu_1} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wGfBzc7WOwhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1cd5f7-8e6b-4a42-cc06-7e99009ac6fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speedup = 12.920981168517624\n"
          ]
        }
      ],
      "source": [
        "speedup = t_cpu / t_gpu_atom\n",
        "print(f\"Speedup = {speedup}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}